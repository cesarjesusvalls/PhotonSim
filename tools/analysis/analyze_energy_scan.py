#!/usr/bin/env python3
"""
Analyze the energy scan results from PhotonSim.

This script reads the ROOT files generated by the energy scan and analyzes
the photon time vs distance histograms for different muon energies.
"""

import ROOT
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import sys
import argparse

def predict_timing(distance, energy, params, debug=False):
    """
    Predict average photon creation time using the parameterization.
    
    Returns both total time and delta component.
    
    For 1000 MeV: t(d, 1000) = baseline(d), delta = 0 (reference energy)
    For other energies: t(d, E) = baseline(d) + δt(d, E)
    where:
    - baseline(d) = slope * d + intercept (from 1000 MeV fit)
    - δt(d, E) = 10^(A_slope*E + A_intercept) * d^(B_slope*E + B_intercept) + offset
    
    Returns:
        tuple: (total_time, delta_time)
    """
    # Baseline from 1000 MeV linear fit
    baseline = params['baseline_1000MeV']['slope'] * distance + params['baseline_1000MeV']['intercept']
    
    # For other energies, calculate delta timing
    delta_params = params['delta_parameterization']
    log10_A = delta_params['A_slope'] * energy + delta_params['A_intercept']
    B = delta_params['B_slope'] * energy + delta_params['B_intercept']
    delta = 10**log10_A * np.power(distance, B) + delta_params['offset']
    
    if debug and isinstance(distance, (int, float)) and distance == 1000:
        print(f"\\nDebug for E={energy} MeV, d={distance} mm:")
        print(f"  Baseline: {params['baseline_1000MeV']['slope']:.6f} * {distance} + {params['baseline_1000MeV']['intercept']:.3f} = {baseline:.3f}")
        print(f"  log10(A): {delta_params['A_slope']:.6f} * {energy} + {delta_params['A_intercept']:.3f} = {log10_A:.3f}")
        print(f"  B: {delta_params['B_slope']:.6f} * {energy} + {delta_params['B_intercept']:.3f} = {B:.3f}")
        print(f"  Delta: 10^{log10_A:.3f} * {distance}^{B:.3f} + {delta_params['offset']} = {delta:.6f}")
        print(f"  Total: {baseline:.3f} + {delta:.6f} = {baseline + delta:.3f}")
    
    # Return both total timing and delta
    return baseline + delta, delta

def create_prediction_plot(params, output_dir, all_timing_data, valid_range_values, valid_energies):
    """Create plot of timing predictions for all energies with data overlay."""
    
    # Create figure
    fig_pred, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Colors for different energies
    energies = params['energy_range']['values']
    colors = plt.cm.viridis(np.linspace(0, 1, len(energies)))
    
    # Create energy to range mapping
    range_dict = {}
    for i, energy in enumerate(valid_energies):
        range_dict[energy] = valid_range_values[i]
    
    # Plot 1: Full predicted timing curves with data overlay
    for i, energy in enumerate(energies):
        color = colors[i]
        
        # Get the range for this energy (limit prediction to expected range)
        if energy in range_dict:
            max_distance = min(range_dict[energy], 5000)  # Cap at 5000mm for plotting
        else:
            max_distance = 5000  # Use full range for energies not in range_dict (like 1000 MeV)
        
        # Create prediction curve only up to the expected range
        distances = np.linspace(0, max_distance, 100)
        try:
            times, deltas = predict_timing(distances, energy, params)
        except Exception as e:
            print(f"Error in predict_timing for energy {energy}: {e}")
            continue
        
        # Plot prediction curve for total timing
        ax1.plot(distances, times, '-', color=color, linewidth=4, 
                label=f'{energy} MeV prediction', alpha=0.4)
        
        # Plot prediction curve for delta timing
        ax2.plot(distances, deltas, '-', color=color, linewidth=4, 
                label=f'{energy} MeV prediction', alpha=0.4)
        
        # Overlay original data points
        timing_data = None
        for td in all_timing_data:
            if td['energy'] == energy:
                timing_data = td
                break
        
        if timing_data is not None:
            # Plot original timing data
            ax1.scatter(timing_data['distances'], timing_data['times'], 
                       color=color, s=5, alpha=1, marker='x',
                       label=f'{energy} MeV data')
            
            # Plot delta data
            # Calculate delta from original data (actual - baseline)
            baseline_times = (params['baseline_1000MeV']['slope'] * np.array(timing_data['distances']) + 
                            params['baseline_1000MeV']['intercept'])
            delta_data = np.array(timing_data['times']) - baseline_times
            
            ax2.scatter(timing_data['distances'], delta_data, 
                       color=color, s=1, alpha=0.7, zorder=5,
                       label=f'{energy} MeV data')
    
    ax1.set_xlabel('Distance from Origin (mm)', fontsize=12)
    ax1.set_ylabel('Average Photon Creation Time (ns)', fontsize=12)
    # ax1.grid(True, alpha=0.3)
    ax1.set_xlim(0, None)
    ax1.set_ylim(0, None)
    
    ax2.set_xlabel('Distance from Origin (mm)', fontsize=12)
    ax2.set_ylabel('Timing Delta (ns)', fontsize=12)
    # ax2.grid(True, alpha=0.3)
    ax2.set_xlim(0, None)
    
    # Create shared legend on top of the figure
    handles, labels = ax1.get_legend_handles_labels()
    fig_pred.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.2), 
                   ncol=5, fontsize=10)
    
    fig_pred.tight_layout()
    
    # Save plot
    output_file = output_dir / "timing_predictions.png"
    plt.figure(fig_pred.number)
    fig_pred.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"\\nPrediction plot saved to: {output_file}")
    
    # Print parameterization info
    print("\\n=== Timing Prediction Summary ===")
    print(f"Generated predictions for {len(energies)} energies from {min(energies)} to {max(energies)} MeV")
    print(f"Each energy limited to its expected muon range")
    print(f"Left plot: Complete timing (baseline + delta) vs original data")
    print(f"Right plot: Delta timing only (excluding 1000 MeV reference) vs delta data")
    
    return fig_pred

def analyze_energy_scan(scan_directory):
    """Analyze the energy scan results."""
    
    scan_dir = Path(scan_directory)
    if not scan_dir.exists():
        print(f"Error: Directory {scan_dir} not found!")
        return
    
    # Find all ROOT files matching the pattern
    root_files = list(scan_dir.glob("muons_*MeV_scan.root"))
    
    if not root_files:
        print(f"Error: No scan ROOT files found in {scan_dir}")
        return
    
    # Sort files by energy
    def extract_energy(filename):
        # Extract energy from filename like "muons_100MeV_scan.root"
        try:
            energy_str = filename.stem.split('_')[1].replace('MeV', '')
            return int(energy_str)
        except:
            return 0
    
    root_files.sort(key=extract_energy)
    
    print(f"=== Energy Scan Analysis ===")
    print(f"Found {len(root_files)} energy scan files")
    print(f"Energy range: {extract_energy(root_files[0])} - {extract_energy(root_files[-1])} MeV")
    
    # Create main figure with two subplots for timing analysis
    fig_main, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    # Create separate figure for range analysis
    fig_range, (ax3, ax4) = plt.subplots(1, 2, figsize=(12, 4))
    
    energies = []
    ranges = []  # Store calculated ranges for each energy
    all_timing_data = []  # Store timing data for remaining range analysis
    
    # Colors for different energies
    colors = plt.cm.viridis(np.linspace(0, 1, len(root_files)))

    # Process each energy
    for i, root_file in enumerate(root_files):
        energy = extract_energy(root_file)
        energies.append(energy)
        
        print(f"\\nProcessing {energy} MeV...")
        
        # Open ROOT file
        f = ROOT.TFile.Open(str(root_file), "READ")
        if not f or f.IsZombie():
            print(f"  Error: Cannot open {root_file}")
            continue
        
        # Get the photon time vs distance histogram
        hist = f.Get("PhotonHist_TimeDistance")
        if not hist:
            print(f"  Error: PhotonHist_TimeDistance not found in {root_file}")
            f.Close()
            continue
        
        # Get the tree to determine actual number of events
        tree = f.Get("OpticalPhotons")
        if not tree:
            print(f"  Error: OpticalPhotons tree not found in {root_file}")
            f.Close()
            continue
        
        # Get actual number of events
        n_events = tree.GetEntries()
        print(f"  Events: {n_events}")
        
        # Calculate mean time vs distance (profile)
        n_bins_x = hist.GetNbinsX()
        n_bins_y = hist.GetNbinsY()
        
        # Calculate statistics
        n_entries = hist.GetEntries()
        print(f"  Photons: {n_entries:,}")
        
        # Create profiles: mean time vs distance AND photon count vs distance
        distances_time = []
        mean_times = []
        distances_count = []
        photon_counts = []
        
        for bin_x in range(1, n_bins_x + 1):
            distance = hist.GetXaxis().GetBinCenter(bin_x)
            
            # Calculate mean time for this distance bin
            total_time_weighted = 0
            total_weight = 0
            
            for bin_y in range(1, n_bins_y + 1):
                content = hist.GetBinContent(bin_x, bin_y)
                if content > 0:
                    time = hist.GetYaxis().GetBinCenter(bin_y)
                    total_time_weighted += content * time
                    total_weight += content
            
            # Store time data (only if we have at least 10 photons on average)
            avg_photons_in_bin = total_weight / n_events
            if avg_photons_in_bin >= 10.0:
                mean_time = total_time_weighted / total_weight
                distances_time.append(distance)
                mean_times.append(mean_time)
            
            # Store count data (total photons in this distance bin)
            if total_weight > 0:
                distances_count.append(distance)
                photon_counts.append(total_weight)
        
        # Plot 1: mean time vs distance for this energy
        if len(distances_time) > 0:
            ax1.plot(distances_time, mean_times, color=colors[i], alpha=0.8, 
                    label=f'{energy} MeV', linewidth=2, marker='o', markersize=2)
            
            # Store timing data for remaining range analysis
            all_timing_data.append({
                'energy': energy,
                'distances': distances_time,
                'times': mean_times,
                'color': colors[i]
            })
        
        # Calculate average photon count per event for this energy
        if len(distances_count) > 0:
            # Use actual number of events read from the file
            avg_photon_counts = [count / n_events for count in photon_counts]
            
            # Plot 3: average photon count vs distance (moved to range figure)
            ax3.plot(distances_count, avg_photon_counts, color=colors[i], alpha=0.8, 
                    label=f'{energy} MeV', linewidth=2, marker='o', markersize=2)
            
            # Calculate range using filtered data (10-500 average photons per event)
            if len(distances_count) > 2:
                # Filter data: use only points with 10-500 average photons per event
                filtered_data = [(d, c) for d, c in zip(distances_count, avg_photon_counts) 
                               if 10 <= c <= 500]
                
                if len(filtered_data) >= 3:  # Need at least 3 points for fitting
                    filtered_distances, filtered_counts = zip(*filtered_data)
                    filtered_distances = np.array(filtered_distances)
                    filtered_counts = np.array(filtered_counts)
                    
                    # Sort by distance to ensure proper ordering
                    sort_idx = np.argsort(filtered_distances)
                    filtered_distances = filtered_distances[sort_idx]
                    filtered_counts = filtered_counts[sort_idx]
                    
                    try:
                        # Linear fit: avg_count = a * distance + b
                        coeffs = np.polyfit(filtered_distances, filtered_counts, 1)
                        a, b = coeffs
                        
                        # Calculate range (distance where avg_count = 0)
                        if a < 0:  # Slope should be negative
                            calculated_range = -b / a
                            ranges.append(calculated_range)
                            
                            # Plot the fit line
                            fit_line_x = np.linspace(filtered_distances[0], calculated_range, 100)
                            fit_line_y = a * fit_line_x + b
                            # Only plot positive part
                            positive_mask = fit_line_y >= 0
                            ax3.plot(fit_line_x[positive_mask], fit_line_y[positive_mask], 
                                    '--', color=colors[i], alpha=0.5, linewidth=1)
                            
                            # Mark the calculated range
                            ax3.axvline(x=calculated_range, color=colors[i], 
                                       linestyle=':', alpha=0.7, linewidth=1)
                            
                            # Highlight the data points used for fitting
                            ax3.scatter(filtered_distances, filtered_counts, 
                                      color=colors[i], alpha=0.3, s=20, marker='s')
                            
                            print(f"  Calculated range: {calculated_range:.1f} mm (using {len(filtered_data)} points)")
                        else:
                            ranges.append(np.nan)
                            print(f"  Could not calculate range (positive slope)")
                    except:
                        ranges.append(np.nan)
                        print(f"  Could not calculate range (fit failed)")
                else:
                    ranges.append(np.nan)
                    print(f"  Could not calculate range (only {len(filtered_data)} points in 100-5000 range)")
            else:
                ranges.append(np.nan)
                print(f"  Could not calculate range (too few data points)")
        
        f.Close()

    print('Energies: ', energies)
    
    # Save summary data with ranges
    summary_file = scan_dir / "energy_scan_summary.txt"
    with open(summary_file, 'w') as f:
        f.write("Energy Scan Summary\\n")
        f.write("==================\\n\\n")
        f.write("Energy (MeV)  Calculated Range (mm)\\n")
        f.write("-" * 35 + "\\n")
        for i, energy in enumerate(energies):
            if i < len(ranges):
                range_str = f"{ranges[i]:.1f}" if not np.isnan(ranges[i]) else "N/A"
            else:
                range_str = "N/A"
            f.write(f"{energy:8d}  {range_str:>15s}\\n")
        f.write("\\nTiming analysis figure:\\n")
        f.write("- Left plot: Average photon creation time vs distance\\n")
        f.write("- Right plot: Timing delta vs distance with power law fits\\n")
        f.write("\\nRange analysis figure:\\n")
        f.write("- Left plot: Average photon count per event vs distance with range calculations\\n")
        f.write("- Right plot: Muon range vs energy with linear fit\\n")
        f.write("\\nRange calculation method:\\n")
        f.write("- Use only data points with 100-5000 average photons per event\\n")
        f.write("- Fit linear line to filtered data: avg_count = a*distance + b\\n")
        f.write("- Find intercept where avg_count = 0: range = -b/a\\n")
        f.write("- Dashed lines show fits, dotted lines show calculated ranges\\n")
        f.write("- Square markers highlight data points used in fit\\n")
    
    print(f"Summary saved to: {summary_file}")
    
    # Create range analysis and remaining range plot
    valid_ranges = [(e, r) for e, r in zip(energies, ranges) if not np.isnan(r)]
    if len(valid_ranges) > 2:
        valid_energies, valid_range_values = zip(*valid_ranges)
        
        print(f"\\n=== Range Analysis ===")
        print("Calculated ranges:")
        for energy, range_val in valid_ranges:
            print(f"  {energy:4d} MeV: {range_val:6.1f} mm")
        
        # Plot 4: Range vs Energy (moved to ax4)
        ax4.scatter(valid_energies, valid_range_values, color='red', s=50, alpha=0.7, zorder=3)
        
        # Linear fit only (as requested)
        try:
            # Linear fit (keep in mm)
            linear_coeffs = np.polyfit(valid_energies, valid_range_values, 1)
            a_lin, b_lin = linear_coeffs
            
            # Calculate R-squared for linear fit
            linear_pred = a_lin * np.array(valid_energies) + b_lin
            ss_res_lin = np.sum((valid_range_values - linear_pred) ** 2)
            ss_tot = np.sum((valid_range_values - np.mean(valid_range_values)) ** 2)
            r2_linear = 1 - (ss_res_lin / ss_tot)
            
            # Plot linear fit
            energy_fit = np.linspace(min(valid_energies), max(valid_energies), 100)
            linear_fit = a_lin * energy_fit + b_lin
            ax4.plot(energy_fit, linear_fit, '--', color='blue', linewidth=2, 
                    label=f'R = {a_lin:.3f}E + {b_lin:.1f} (R² = {r2_linear:.3f})', alpha=0.8)
            
            # Add legend to ax4
            ax4.legend(fontsize=10)
            
            print(f"\\nLinear fit: R = {a_lin:.3f}*E + {b_lin:.1f} mm (R² = {r2_linear:.3f})")
            
            # New timing delta analysis with power law fits
            print(f"\\n=== Power Law Timing Delta Analysis ===")
            
            # Find 1000 MeV data for reference timing fit
            timing_1000_data = None
            for timing_data in all_timing_data:
                if timing_data['energy'] == 1000:
                    timing_1000_data = timing_data
                    break
            
            if timing_1000_data is not None:
                # Fit timing vs distance for 1000 MeV using only first 1000mm
                distances_1000 = np.array(timing_1000_data['distances'])
                times_1000 = np.array(timing_1000_data['times'])
                
                # Filter to first 1000mm
                mask_1000mm = distances_1000 <= 1000.0
                if np.any(mask_1000mm):
                    dist_fit = distances_1000[mask_1000mm]
                    time_fit = times_1000[mask_1000mm]
                    
                    # Linear fit: time = c * distance + d
                    timing_coeffs = np.polyfit(dist_fit, time_fit, 1)
                    c_timing, d_timing = timing_coeffs
                    
                    print(f"  1000 MeV timing fit (first 1000mm): t = {c_timing:.6f}*d + {d_timing:.3f}")
                    
                    # Store power law fit parameters for each energy
                    power_law_params = []
                    
                    # Calculate deltas and fit power laws for all energies
                    for timing_data in all_timing_data:
                        energy = timing_data['energy']
                        distances = np.array(timing_data['distances'])
                        times = np.array(timing_data['times'])
                        color = timing_data['color']
                        
                        # Calculate expected timing using 1000 MeV fit
                        expected_timing = c_timing * distances + d_timing
                        
                        # Calculate timing delta (actual - expected)
                        timing_delta = times - expected_timing
                        
                        # Plot timing delta vs distance (not remaining range)
                        ax2.plot(distances, timing_delta, color=color, alpha=0.6, 
                                linewidth=0, marker='o', markersize=2, label=f'{energy} MeV data')
                        
                        # Fit power law with offset: δt = A * d^B + C
                        valid_mask = (distances > 0) & (np.abs(timing_delta) > 0.001)
                        if np.sum(valid_mask) >= 4:  # Need at least 4 points for 3 parameters
                            distances_fit = distances[valid_mask]
                            delta_fit = timing_delta[valid_mask]
                            
                            try:
                                # Use scipy's curve_fit for the general power law form
                                from scipy.optimize import curve_fit
                                
                                def power_law_offset(x, A, B):
                                    return 10**A * np.power(x, B) + 0.001
                                
                                # Initial guess: A=log10(1e-3)=-3, B=1.5
                                p0 = [-3, 1.5]
                                
                                # Fit the power law with fixed offset
                                popt, pcov = curve_fit(power_law_offset, distances_fit, delta_fit, 
                                                     p0=p0, maxfev=5000)
                                A, B = popt
                                
                                # Calculate R²
                                y_pred = power_law_offset(distances_fit, A, B)
                                ss_res = np.sum((delta_fit - y_pred) ** 2)
                                ss_tot = np.sum((delta_fit - np.mean(delta_fit)) ** 2)
                                r2 = 1 - (ss_res / ss_tot)
                                
                                # Plot the fit
                                x_fit = np.linspace(distances_fit.min(), distances_fit.max(), 100)
                                y_fit = power_law_offset(x_fit, A, B)
                                
                                # Format the equation
                                formula = f'δt = 10^{A:.3f}×d^{B:.3f} + 0.001'
                                
                                ax2.plot(x_fit, y_fit, '--', color=color, alpha=0.8, linewidth=2,
                                        label=f'{energy} MeV: {formula} (R²={r2:.3f})')
                                
                                power_law_params.append({'energy': energy, 'A': A, 'B': B, 'r2': r2})
                                
                                print(f"  {energy:4d} MeV: {formula}, R² = {r2:.3f}")
                                
                            except Exception as e:
                                print(f"  {energy:4d} MeV: Power law fit failed - {e}")
                        else:
                            print(f"  {energy:4d} MeV: Not enough valid points for fitting")
                            
                    # Show summary of power law parameters
                    if power_law_params:
                        print(f"\\n=== Power Law Parameter Summary ===")
                        print("Energy (MeV)   log10(A)      B        R²")
                        print("-" * 45)
                        for params in power_law_params:
                            print(f"{params['energy']:8d}  {params['A']:10.3f}  {params['B']:7.3f}  {params['r2']:6.3f}")
                        
                        # Analyze trends in parameters
                        energies = [p['energy'] for p in power_law_params]
                        A_values = [p['A'] for p in power_law_params]
                        B_values = [p['B'] for p in power_law_params]
                        
                        print(f"\\n=== Parameter Trends ===")
                        print(f"log₁₀(A) range: {min(A_values):.3f} to {max(A_values):.3f}")
                        print(f"B range: {min(B_values):.3f} to {max(B_values):.3f}")
                        print(f"Fixed offset C = 0.001")
                        
                        # Fit parameter trends as functions of energy
                        try:
                            # For log10(A): try linear fit log10(A) = m * E + c
                            m_A, c_A = np.polyfit(energies, A_values, 1)
                            
                            # Verify the fit
                            A_pred = m_A * np.array(energies) + c_A
                            ss_res_A = np.sum((A_values - A_pred) ** 2)
                            ss_tot_A = np.sum((A_values - np.mean(A_values)) ** 2)
                            r2_A = 1 - (ss_res_A / ss_tot_A)
                            
                            print(f"\\n=== log10(A) Parameter Fit ===")
                            print(f"log10(A) = {m_A:.6f} × E + {c_A:.3f}")
                            print(f"R² = {r2_A:.4f}")
                            
                            # For B: try linear fit B = m * E + c
                            m_B, c_B = np.polyfit(energies, B_values, 1)
                            
                            # Verify the fit
                            B_pred = m_B * np.array(energies) + c_B
                            ss_res_B = np.sum((B_values - B_pred) ** 2)
                            ss_tot_B = np.sum((B_values - np.mean(B_values)) ** 2)
                            r2_B = 1 - (ss_res_B / ss_tot_B)
                            
                            print(f"\\n=== B Parameter Fit ===")
                            print(f"B(E) = {m_B:.6f} × E + {c_B:.3f}")
                            print(f"R² = {r2_B:.4f}")
                            
                            # Create a third figure for parameter trends
                            fig_params = plt.figure(figsize=(12, 4))
                            ax_A = fig_params.add_subplot(121)
                            ax_B = fig_params.add_subplot(122)
                            
                            # Plot log10(A) parameter trend
                            ax_A.scatter(energies, A_values, color='red', s=50, label='Data')
                            E_fit = np.linspace(min(energies), max(energies), 100)
                            A_fit = m_A * E_fit + c_A
                            ax_A.plot(E_fit, A_fit, 'b--', linewidth=2, 
                                     label=f'log₁₀(A) = {m_A:.4f}×E + {c_A:.2f}')
                            ax_A.set_xlabel('Energy (MeV)', fontsize=12)
                            ax_A.set_ylabel('log₁₀(A)', fontsize=12)
                            ax_A.set_title('Power Law log₁₀(Amplitude) vs Energy', fontsize=14)
                            #ax_A.set_xscale('log')
                            #ax_A.grid(True, alpha=0.3)
                            ax_A.legend()
                            
                            # Plot B parameter trend
                            ax_B.scatter(energies, B_values, color='red', s=50, label='Data')
                            B_fit = m_B * E_fit + c_B
                            ax_B.plot(E_fit, B_fit, 'b--', linewidth=2, 
                                     label=f'B = {m_B:.4f}×E + {c_B:.3f}')
                            ax_B.set_xlabel('Energy (MeV)', fontsize=12)
                            ax_B.set_ylabel('B Parameter', fontsize=12)
                            ax_B.set_title('Power Law Exponent vs Energy', fontsize=14)
                            #ax_B.grid(True, alpha=0.3)
                            ax_B.legend()
                            
                            fig_params.tight_layout()
                            
                            # Save parameter trends plot
                            output_plot_params = scan_dir / "parameter_trends.png"
                            plt.figure(fig_params.number)
                            fig_params.savefig(output_plot_params, dpi=150, bbox_inches='tight')
                            print(f"\\nParameter trends plot saved to: {output_plot_params}")
                            
                            # Final parameterization
                            print(f"\\n=== Complete Timing Delta Parameterization ===")
                            print(f"δt(d, E) = 10^A(E) × d^B(E) + 0.001")
                            print(f"where:")
                            print(f"  log₁₀(A) = {m_A:.6f} × E + {c_A:.3f}")
                            print(f"  B(E) = {m_B:.6f} × E + {c_B:.3f}")
                            print(f"\\nThis gives:")
                            print(f"δt(d, E) = 10^({m_A:.6f}×E + {c_A:.3f}) × d^({m_B:.6f}×E + {c_B:.3f}) + 0.001")
                            
                            # Save all parameters to JSON file
                            import json
                            param_dict = {
                                "baseline_1000MeV": {
                                    "slope": c_timing,
                                    "intercept": d_timing,
                                    "description": "Linear fit for 1000 MeV: t = slope * d + intercept"
                                },
                                "delta_parameterization": {
                                    "A_slope": m_A,
                                    "A_intercept": c_A,
                                    "B_slope": m_B,
                                    "B_intercept": c_B,
                                    "offset": 0.001,
                                    "description": "δt(d, E) = 10^(A_slope*E + A_intercept) * d^(B_slope*E + B_intercept) + offset"
                                },
                                "energy_range": {
                                    "min": min(energies),
                                    "max": max(energies),
                                    "values": energies
                                },
                                "individual_fits": [
                                    {
                                        "energy": p['energy'],
                                        "log10_A": p['A'],
                                        "B": p['B'],
                                        "r2": p['r2']
                                    } for p in power_law_params
                                ]
                            }
                            
                            json_file = scan_dir / "timing_parameters.json"
                            with open(json_file, 'w') as f:
                                json.dump(param_dict, f, indent=4)
                            print(f"\\nParameters saved to: {json_file}")
                            
                            # Generate prediction plot using the parameters
                            create_prediction_plot(param_dict, scan_dir, all_timing_data, valid_range_values, valid_energies)
                            
                        except Exception as e:
                            print(f"\\nParameter trend fitting failed: {e}")
                            
                else:
                    print("  Warning: No 1000 MeV data found within first 1000mm")
            else:
                print("  Warning: No 1000 MeV data found for timing reference")
            
        except Exception as e:
            print(f"  Could not fit range vs energy relationship: {e}")
    else:
        print(f"\\nNot enough valid ranges ({len(valid_ranges)}) to create range analysis")
    
    # Format and save figures after all data is plotted
    # Format the main timing analysis plots
    ax1.set_xlabel('Distance from Origin (mm)', fontsize=12)
    ax1.set_ylabel('Average Photon Creation Time (ns)', fontsize=12)
    ax1.set_title('Average Photon Creation Time vs Distance', fontsize=14)
    ax1.legend(fontsize=9)
    ax1.set_xlim(0, None)
    ax1.set_ylim(0, None)
    
    # Format timing delta plot
    ax2.set_xlabel('Distance from Origin (mm)', fontsize=12)
    ax2.set_ylabel('Timing Delta (ns)', fontsize=12)
    ax2.set_title('Timing Delta vs Distance with Power Law Fits', fontsize=14)
    ax2.set_xlim(0, None)
    
    # Format the range analysis plots
    ax3.set_xlabel('Distance from Origin (mm)', fontsize=12)
    ax3.set_ylabel('Average Photons per Event', fontsize=12)
    ax3.set_title('Average Photon Count vs Distance and Calculated Ranges', fontsize=14)
    ax3.legend(fontsize=9)
    ax3.set_xlim(0, None)
    ax3.set_ylim(0, None)
    
    # Format range vs energy plot
    ax4.set_xlabel('Energy (MeV)', fontsize=12)
    ax4.set_ylabel('Range (mm)', fontsize=12)
    ax4.set_title('Muon Range vs Energy', fontsize=14)
    ax4.grid(True, alpha=0.3)
    ax4.set_xlim(0, None)
    ax4.set_ylim(0, None)
    
    fig_main.tight_layout()
    fig_range.tight_layout()
    
    # Save plots after all data is plotted and formatted
    output_plot_main = scan_dir / "timing_analysis.png"
    plt.figure(fig_main.number)
    fig_main.savefig(output_plot_main, dpi=150, bbox_inches='tight')
    print(f"\\nTiming analysis plot saved to: {output_plot_main}")
    
    output_plot_range = scan_dir / "range_analysis.png"
    plt.figure(fig_range.number)
    fig_range.savefig(output_plot_range, dpi=150, bbox_inches='tight')
    print(f"Range analysis plot saved to: {output_plot_range}")
    
    # Show all plots after everything is saved
    plt.show()

def main():
    """Main function."""
    
    parser = argparse.ArgumentParser(description='Analyze energy scan results')
    parser.add_argument('scan_directory', nargs='?', default='energy_scan_macros',
                        help='Directory containing scan ROOT files')
    
    args = parser.parse_args()
    
    analyze_energy_scan(args.scan_directory)

if __name__ == "__main__":
    main()